{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "df = pd.read_csv('data.csv')\n",
    "\n",
    "# Group by Disaster Type and Start Year and sum the required columns\n",
    "grouped_df = df.groupby(['Disaster Type', 'Start Year']).agg({\n",
    "    \"Total Damage, Adjusted ('000 US$)\": 'sum',\n",
    "    'Total Deaths': 'sum',\n",
    "    'Total Affected': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Save the grouped data to a new CSV file\n",
    "grouped_df.to_csv('data_grouped.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV data\n",
    "df = pd.read_csv('data_grouped.csv')\n",
    "\n",
    "# Select relevant columns\n",
    "selected_columns = ['Disaster Type', 'Start Year', \"Total Damage, Adjusted ('000 US$)\", 'Total Deaths', 'Total Affected']\n",
    "df_selected = df[selected_columns]\n",
    "\n",
    "# Convert to JSON\n",
    "json_data = df_selected.to_json(orient='records')\n",
    "\n",
    "# Save JSON to a file\n",
    "with open('data.json', 'w') as f:\n",
    "    f.write(json_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Air', 'Animal incident', 'Chemical spill',\n",
       "       'Collapse (Industrial)', 'Collapse (Miscellaneous)', 'Drought',\n",
       "       'Earthquake', 'Epidemic', 'Explosion (Industrial)',\n",
       "       'Explosion (Miscellaneous)', 'Extreme temperature',\n",
       "       'Fire (Industrial)', 'Fire (Miscellaneous)', 'Flood', 'Fog',\n",
       "       'Gas leak', 'Glacial lake outburst flood', 'Impact',\n",
       "       'Industrial accident (General)', 'Infestation',\n",
       "       'Mass movement (dry)', 'Mass movement (wet)',\n",
       "       'Miscellaneous accident (General)', 'Oil spill', 'Poisoning',\n",
       "       'Radiation', 'Rail', 'Road', 'Storm', 'Volcanic activity', 'Water',\n",
       "       'Wildfire'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the CSV data\n",
    "df = pd.read_csv('data_grouped.csv')\n",
    "\n",
    "\n",
    "df['Disaster Type'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Values to filter\n",
    "filter_values = ['Earthquake', 'Extreme temperature', 'Flood', 'Wildfire', 'Storm', 'Volcanic activity']\n",
    "\n",
    "# Filter the DataFrame\n",
    "filtered_df = df[df['Disaster Type'].isin(filter_values)]\n",
    "\n",
    "# Save the DataFrame as a CSV file\n",
    "filtered_df.to_csv('filtered_disaster_types.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accumulate values up to each year\n",
    "accumulated_df = filtered_df.copy()\n",
    "accumulated_df.sort_values(by=['Disaster Type', 'Start Year'], inplace=True)\n",
    "accumulated_df['Total Damage, Adjusted (\\'000 US$)'] = accumulated_df.groupby('Disaster Type')[\"Total Damage, Adjusted ('000 US$)\"].cumsum()\n",
    "accumulated_df['Total Deaths'] = accumulated_df.groupby('Disaster Type')['Total Deaths'].cumsum()\n",
    "accumulated_df['Total Affected'] = accumulated_df.groupby('Disaster Type')['Total Affected'].cumsum()\n",
    "\n",
    "# Save the accumulated DataFrame as a CSV file\n",
    "accumulated_df.to_csv('accumulated_disaster_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  group.fillna(method='ffill', inplace=True)\n",
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  group.fillna(method='ffill', inplace=True)\n",
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  group.fillna(method='ffill', inplace=True)\n",
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  group.fillna(method='ffill', inplace=True)\n",
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  group.fillna(method='ffill', inplace=True)\n",
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:7: FutureWarning: DataFrame.fillna with 'method' is deprecated and will raise in a future version. Use obj.ffill() or obj.bfill() instead.\n",
      "  group.fillna(method='ffill', inplace=True)\n",
      "/var/folders/nx/j902lz2j46z6vbkybc_06t080000gn/T/ipykernel_24810/3221156206.py:11: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  filled_df = accumulated_df.groupby('Disaster Type').apply(add_missing_years).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "# Add missing years with the same values as the previous year\n",
    "def add_missing_years(group):\n",
    "    min_year = group['Start Year'].min()\n",
    "    max_year = group['Start Year'].max()\n",
    "    all_years = pd.DataFrame({'Start Year': np.arange(min_year, max_year + 1)})\n",
    "    group = all_years.merge(group, on='Start Year', how='left')\n",
    "    group.fillna(method='ffill', inplace=True)\n",
    "    return group\n",
    "\n",
    "# Apply the function to each disaster type group\n",
    "filled_df = accumulated_df.groupby('Disaster Type').apply(add_missing_years).reset_index(drop=True)\n",
    "\n",
    "# Save the filled DataFrame as a CSV file\n",
    "filled_df.to_csv('filled_disaster_data.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to the specified JSON format\n",
    "result = []\n",
    "for disaster_type, group in filled_df.groupby('Disaster Type'):\n",
    "    entry = {\n",
    "        \"name\": disaster_type,\n",
    "        \"Total Damage, Adjusted ('000 US$)\": group[['Start Year', \"Total Damage, Adjusted ('000 US$)\"]].values.tolist(),\n",
    "        'Total Affected': group[['Start Year', 'Total Affected']].values.tolist(),\n",
    "        'Total Deaths': group[['Start Year', 'Total Deaths']].values.tolist()\n",
    "    }\n",
    "    result.append(entry)\n",
    "\n",
    "# Save the result to a JSON file\n",
    "with open('accumulated_disaster_data_all_years.json', 'w') as json_file:\n",
    "    json.dump(result, json_file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter to include only years after 1950\n",
    "filtered_filled_df = filled_df[filled_df['Start Year'] >= 1950]\n",
    "\n",
    "# Convert to the specified JSON format\n",
    "result = []\n",
    "for disaster_type, group in filtered_filled_df.groupby('Disaster Type'):\n",
    "    entry = {\n",
    "        \"name\": disaster_type,\n",
    "        \"Total Damage, Adjusted ('000 US$)\": group[['Start Year', \"Total Damage, Adjusted ('000 US$)\"]].values.tolist(),\n",
    "        'Total Affected': group[['Start Year', 'Total Affected']].values.tolist(),\n",
    "        'Total Deaths': group[['Start Year', 'Total Deaths']].values.tolist()\n",
    "    }\n",
    "    result.append(entry)\n",
    "\n",
    "# Save the result to a JSON file\n",
    "with open('accumulated_disaster_data_1950.json', 'w') as json_file:\n",
    "    json.dump(result, json_file, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
